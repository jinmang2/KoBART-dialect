python train.py st \
    --report_to wandb \
    --run_name style_transfer \
    --output_dir outputs \
    --evaluation_strategy steps \
    --save_strategy steps \
    --per_device_train_batch_size 64 \
    --per_device_eval_batch_size 64 \
    --lr_scheduler_type cosine \
    --learning_rate 3e-5 \
    --adam_beta2 0.98 \
    --adam_epsilon 1e-09 \
    --max_steps 100000 \
    --eval_steps 5000 \
    --save_steps 5000 \
    --save_total_limit 5 \
    --seed 42 \
    --fp16 False \
    --warmup_steps 2000 \
    --remove_unused_columns False \
    --temperature 1.0